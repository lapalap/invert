{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Get explanation accuracy for NetDissect and INVERT.\n",
    "\n",
    "The MS COCO dataset requires the COCO API to be installed <https://github.com/cocodataset/cocoapi/tree/master>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import sympy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torchvision.models.segmentation import fcn_resnet50\n",
    "\n",
    "from invert.evaluation import *\n",
    "from invert.explainer import Invert\n",
    "from invert.metrics import Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/root/path/\"\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 2\n",
    "QUANTILE = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "MODEL_NAME = \"fcn_resnet50\" # or \"maskrcnn\"\n",
    "\n",
    "if MODEL_NAME == \"maskrcnn\":\n",
    "    N_NEURONS = 91\n",
    "    N_CLASSES = 91\n",
    "    IMG_SIZE = 224\n",
    "    SUBSET_SIZE = 25000\n",
    "    DATA_NAME = \"coco25k\"\n",
    "    IMAGES_PATH = f\"{ROOT}COCO/images/train2017\"\n",
    "    ANN_PATH = f\"{ROOT}COCO/annotations/instances_train2017.json\"\n",
    "    dataset_full = CocoDataset(root=IMAGES_PATH, annFile=ANN_PATH)\n",
    "    dataset = Subset(dataset_full, range(SUBSET_SIZE))\n",
    "    model = CustomMaskRCNN()\n",
    "elif MODEL_NAME == \"fcn_resnet50\":\n",
    "    N_NEURONS = 21\n",
    "    N_CLASSES = 21\n",
    "    IMG_SIZE = 520\n",
    "    DATA_NAME = \"coco-voc-val\"\n",
    "    IMAGES_PATH = f\"{ROOT}COCO/images/val2017\"\n",
    "    ANN_PATH = f\"{ROOT}COCO/annotations/instances_val2017.json\"\n",
    "    dataset = VocCocoDataset(root=IMAGES_PATH, annFile=ANN_PATH, transforms=SemanticSegmentation(resize_size=[IMG_SIZE,IMG_SIZE]))\n",
    "    model = fcn_resnet50(pretrained=True, progress=False)\n",
    "\n",
    "# Load dataset\n",
    "dataloader = DataLoader(dataset,                        \n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        collate_fn=collate_fn,\n",
    "                        shuffle=False,\n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        )\n",
    "N_BATCHES = len(dataloader)\n",
    "N_DATA = len(dataloader) * BATCH_SIZE\n",
    "\n",
    "# Load model\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. NetDissect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [24:52,  4.77s/it]\n"
     ]
    }
   ],
   "source": [
    "# Determine thresholds for neuron activations for each neuron.\n",
    "quant = QuantileVector(depth=N_NEURONS, seed=1)\n",
    "with torch.no_grad():\n",
    "    for i, (image, mask, image_name, image_label) in tqdm(enumerate(dataloader)):\n",
    "        image = image.to(device, dtype=torch.float32)\n",
    "        if MODEL_NAME == \"maskrcnn\":\n",
    "            output = model(image) # Bx91x224x224\n",
    "        elif MODEL_NAME == \"fcn_resnet50\":\n",
    "            output = model(image)[\"out\"] # Bx21x520x520\n",
    "            # normalize masks to probabilities\n",
    "            output = torch.nn.functional.softmax(output, dim=1)\n",
    "        batch = output.cpu().numpy()\n",
    "        batch = np.transpose(batch, axes=(0, 2, 3, 1)).reshape( \n",
    "            -1, output.shape[1]\n",
    "        )\n",
    "        quant.add(batch)\n",
    "ret = quant.readout(1000)[:, int(1000 * (1 - QUANTILE) - 1)]\n",
    "\n",
    "# If all Quantiles set to 0.5\n",
    "# ret = 0.5 * torch.ones(N_NEURONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [02:28,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 20/21\n",
      "Accuracy: 95.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get IoU scores\n",
    "intersection_all = torch.zeros([N_BATCHES,N_NEURONS,N_CLASSES]).to(device)\n",
    "union_all = torch.zeros([N_BATCHES,N_NEURONS,N_CLASSES]).to(device)\n",
    "output_max_all = torch.zeros([N_DATA,N_CLASSES])\n",
    "if not os.path.exists(\"assets/coco/\"):\n",
    "    os.makedirs(\"assets/coco/\")\n",
    "\n",
    "# Save image names with labels for INVERT\n",
    "with open(f\"assets/coco/{DATA_NAME}_labels.csv\",\"w\") as f1:\n",
    "    writer=csv.writer(f1, delimiter=\",\",lineterminator=\"\\n\",)\n",
    "    column_names = [\"image_names\"]\n",
    "    column_names.extend(list(range(N_NEURONS)))\n",
    "    writer.writerow(column_names)   \n",
    "\n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (image, mask, image_name, image_label) in tqdm(enumerate(dataloader)):\n",
    "            for name, label in zip(image_name, image_label.to(device, dtype=torch.float32)):\n",
    "                row = [name] + [str(int(i)) for i in label.tolist()]\n",
    "                writer.writerow(row) \n",
    "\n",
    "            image = image.to(device, dtype=torch.float32)\n",
    "            mask = mask.to(device, dtype=torch.float32)\n",
    "            if MODEL_NAME == \"maskrcnn\":\n",
    "                output = model(image) # Bx91x224x224\n",
    "            elif MODEL_NAME == \"fcn_resnet50\":\n",
    "                output = model(image)[\"out\"] # Bx21x520x520\n",
    "                # normalize masks to probabilities\n",
    "                output = torch.nn.functional.softmax(output, dim=1)\n",
    "            \n",
    "            # Collect activations for INVERT\n",
    "            output_max_all[counter:counter + image.shape[0],:] = torch.amax(output, dim=(2,3))\n",
    "\n",
    "            binarized_masks = [(output[:, i, :, :] > ret[i]).float() for i in range(ret.shape[0])]\n",
    "            binarized_masks = torch.stack(binarized_masks, dim=1)\n",
    "\n",
    "            intersection = torch.mm(flatten_tens(binarized_masks), torch.transpose(flatten_tens(mask), 0, 1))\n",
    "            intersection = intersection/(IMG_SIZE*IMG_SIZE)\n",
    "            intersection_all[i, :, :] = intersection\n",
    "\n",
    "            union = pairwise_sum(flatten_tens(binarized_masks), flatten_tens(mask))\n",
    "            union = union/(IMG_SIZE*IMG_SIZE)\n",
    "            union = union - intersection\n",
    "            union_all[i, :, :] = union\n",
    "            \n",
    "            counter += image.shape[0]\n",
    "\n",
    "# Save activations for INVERT\n",
    "torch.save(output_max_all, f\".invert/{MODEL_NAME}_output_max.pt\")\n",
    "\n",
    "intersection_all = torch.sum(intersection_all, dim=0) / N_BATCHES\n",
    "union_all = torch.sum(union_all, dim=0) / N_BATCHES\n",
    "iou = intersection_all / union_all\n",
    "\n",
    "# Get accuracy\n",
    "max_values, max_indices = torch.max(iou, dim=1)\n",
    "matches = (max_indices == torch.arange(N_NEURONS).to(device))\n",
    "if MODEL_NAME == \"maskrcnn\":\n",
    "    bool_mask = torch.ones(N_NEURONS, dtype=torch.bool)\n",
    "    bool_mask[empty_coco_classes] = 0\n",
    "    matches = matches[bool_mask]\n",
    "num_matches = matches.sum().item()\n",
    "percentage = (num_matches/len(matches)) * 100\n",
    "\n",
    "print(f\"Number of matches: {int(num_matches)}/{len(matches)}\")\n",
    "print(f\"Accuracy: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.   INVERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(f\"assets/coco/{DATA_NAME}_labels.csv\")\n",
    "\n",
    "one_hot_labels = torch.tensor(df[df.columns[1:]].values)\n",
    "if MODEL_NAME == \"maskrcnn\":\n",
    "    data = coco_idx_class\n",
    "elif MODEL_NAME == \"fcn_resnet50\":\n",
    "    data = voc_idx_class\n",
    "\n",
    "# Load activations\n",
    "A = torch.load(f\".invert/{MODEL_NAME}_output_max.pt\") # CHANGE PATH\n",
    "A = A[:one_hot_labels.size(0), :]\n",
    "\n",
    "# Load INVERT\n",
    "explainer = Invert(\n",
    "        storage_dir=\".invert/\",\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "explainer.load_activations(A=A,\n",
    "                           Labels=one_hot_labels,\n",
    "                           description=data,\n",
    "                           dataset=\"coco\"\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get INVERT explanations for all neurons\n",
    "neuron_explain = {}\n",
    "for i in tqdm(range(N_NEURONS)):\n",
    "    explanation = explainer.explain_representation(i, 1, 1, Metric(), max_fraction=1)\n",
    "    formula = repr(explanation[0][\"formula\"])\n",
    "    if \"~\" not in formula:\n",
    "        neuron_explain[i] = int(formula)\n",
    "    else:\n",
    "        neuron_explain[i] = str(formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 20/21\n",
      "Accuracy: 95.24%\n"
     ]
    }
   ],
   "source": [
    "# Get accuracy\n",
    "count = 0\n",
    "for pred, target in neuron_explain.items():\n",
    "    if MODEL_NAME == \"maskrcnn\":\n",
    "        if target in empty_coco_classes:\n",
    "            continue    \n",
    "    if pred == target:\n",
    "        count +=1\n",
    "if MODEL_NAME == \"maskrcnn\":\n",
    "    total_class = len(neuron_explain) - len(empty_coco_classes)\n",
    "elif MODEL_NAME == \"fcn_resnet50\":\n",
    "    total_class = len(neuron_explain)\n",
    "percentage = (count/total_class) * 100\n",
    "\n",
    "print(f\"Number of matches: {int(count)}/{total_class}\")\n",
    "print(f\"Accuracy: {percentage:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comtorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
